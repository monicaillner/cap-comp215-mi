{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UO4namhuBH3l"
      },
      "source": [
        "COMP 215 - LAB 1\n",
        "----------------\n",
        "#### Name:\n",
        "#### Date:\n",
        "\n",
        "This lab exercise is mostly to introduce some of the power in Jupyter Notebooks.\n",
        "Note that a Notebook is composed of \"cells\" - some are \"text\", like this one, while others are \"code\"\n",
        "\n",
        "##### Lab Objectives\n",
        "\n",
        "* create a 2D time-series plot of earthquake data\n",
        "* review common data types (`int` and `str`) and data structures (`list` and `dict`)\n",
        "* introduce a few new python programming techniques\n",
        "\n",
        "**New Python Concepts**:\n",
        "* *list comprehension* provides a compact way to represent map and filter algorithms\n",
        "* `zip` is a built-in algorithm for combining \"parallel\" linear data structures\n",
        "* `datetime.date` objects represent a calendar date (these are very powerful)\n",
        "\n",
        "As will be usual, the fist code cell, below, simply imports all the modules we'll be using..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests\n",
        "import matplotlib.pyplot as plt\n",
        "import  matplotlib.dates as mdates\n",
        "from datetime import datetime\n",
        "from pprint import pprint    # Pretty Print - built-in python function to nicely format data structures"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DqSJNdSdBH3n",
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:03.507889Z",
          "start_time": "2025-12-31T20:09:03.504951Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "2### Making an API Query\n",
        "We'll start by fetching and inspecting some earthquake data from the USGS API\n",
        "\n",
        "Goals:\n",
        "- Make an API request\n",
        "- Convert the JSON response into a Python dictionary\n",
        "- Inspect the structure of the returned data\n",
        "\n",
        "USGS API Documentation:  https://earthquake.usgs.gov/fdsnws/event/1/#parameters\n",
        "\n",
        "Our first query:\n",
        "  - `format=geojson`       # the format we want the data in\n",
        "  - `starttime=2022-01-01` # the start date (date format: yyyy-mm-dd)\n",
        "  - `minmagnitude=5.0`   # smallest magnitude earthquake we're interested in"
      ],
      "metadata": {
        "collapsed": false,
        "id": "0rnf67FTBH3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USGS_API_URL = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
        "\n",
        "params = dict(\n",
        "    format=\"geojson\",\n",
        "    starttime=\"1970-01-01\",\n",
        "    minmagnitude=7.0,\n",
        ")\n",
        "\n",
        "# make a request (like browsing to a web page) and print the results\n",
        "response = requests.get(USGS_API_URL, params=params)\n",
        "\n",
        "print('Response data type:', type(response.text))\n",
        "response.text[:1000]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Al2T68b2BH3p",
        "outputId": "f0efd684-8acb-477b-b3cf-37b4ef5edc5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.300015Z",
          "start_time": "2025-12-31T20:09:03.530465Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response data type: <class 'str'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"type\":\"FeatureCollection\",\"metadata\":{\"generated\":1768183988000,\"url\":\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=1970-01-01&minmagnitude=7.0\",\"title\":\"USGS Earthquakes\",\"status\":200,\"api\":\"1.14.1\",\"count\":773},\"features\":[{\"type\":\"Feature\",\"properties\":{\"mag\":7.6,\"place\":\"2025 Aomori Prefecture, Japan Earthquake\",\"time\":1765203310397,\"updated\":1767717524892,\"tz\":null,\"url\":\"https://earthquake.usgs.gov/earthquakes/eventpage/us6000rtdt\",\"detail\":\"https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000rtdt&format=geojson\",\"felt\":255,\"cdi\":7.4,\"mmi\":6.911,\"alert\":\"yellow\",\"status\":\"reviewed\",\"tsunami\":1,\"sig\":1077,\"net\":\"us\",\"code\":\"6000rtdt\",\"ids\":\",at00t6yfla,pt25342050,us6000rtdt,usauto6000rtdt,\",\"sources\":\",at,pt,us,usauto,\",\"types\":\",dyfi,earthquake-name,finite-fault,ground-failure,impact-link,impact-text,internal-moment-tensor,internal-origin,losspager,moment-tensor,origin,phase-data,shakemap,\",\"nst\":171,\"dmin\":0.871,\"rms\":0.72,\"gap\":17,\"magT'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "execution_count": 39
    },
    {
      "metadata": {
        "id": "uBQJV7umKux2"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that the response looks like a dictionary, but is actually just a string of text (most data on the web is exchanged as plain text!).  This particular data format is called \"[JSON](https://en.wikipedia.org/wiki/JSON)\"\n",
        "\n",
        "The `json.loads` function \"parses\" such text and loads the data into a dictionary..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = json.loads(response.text)\n",
        "print(f\"Query returned a dict with {len(data)} keys\")\n",
        "print(data.keys())   # pretty-print the keys from dict we got back..."
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "M5wV1C_0BH3q",
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.346966Z",
          "start_time": "2025-12-31T20:09:06.311504Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f59c461c-df1c-4b73-8f14-9958d7780c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query returned a dict with 4 keys\n",
            "dict_keys(['type', 'metadata', 'features', 'bbox'])\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.362741Z",
          "start_time": "2025-12-31T20:09:06.359255Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gsxBDoabKux5",
        "outputId": "5e0f481b-e447-4ac0-a177-1e8c76043187"
      },
      "cell_type": "code",
      "source": [
        "# the list of earthquake data are under the \"features\" key...\n",
        "earthquake_list = data[\"features\"]\n",
        "print(f\"Query returned {len(earthquake_list)} earthquake records.\")\n",
        "# and here is what the start of that list of earthquake records looks like...\n",
        "pprint(earthquake_list[:2])  # do you recall the \"slice\" operation?  If not, look it up in the ThinkCsPy textbook!"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query returned 7204 earthquake records.\n",
            "[{'geometry': {'coordinates': [156.1179, 49.2901, 56.243], 'type': 'Point'},\n",
            "  'id': 'us7000rp2k',\n",
            "  'properties': {'alert': None,\n",
            "                 'cdi': None,\n",
            "                 'code': '7000rp2k',\n",
            "                 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us7000rp2k&format=geojson',\n",
            "                 'dmin': 3.95,\n",
            "                 'felt': None,\n",
            "                 'gap': 120,\n",
            "                 'ids': ',usauto7000rp2k,us7000rp2k,',\n",
            "                 'mag': 5.1,\n",
            "                 'magType': 'mb',\n",
            "                 'mmi': None,\n",
            "                 'net': 'us',\n",
            "                 'nst': 75,\n",
            "                 'place': '154 km S of Severo-Kuril’sk, Russia',\n",
            "                 'rms': 0.71,\n",
            "                 'sig': 400,\n",
            "                 'sources': ',usauto,us,',\n",
            "                 'status': 'reviewed',\n",
            "                 'time': 1768160276651,\n",
            "                 'title': 'M 5.1 - 154 km S of Severo-Kuril’sk, Russia',\n",
            "                 'tsunami': 0,\n",
            "                 'type': 'earthquake',\n",
            "                 'types': ',internal-moment-tensor,origin,phase-data,',\n",
            "                 'tz': None,\n",
            "                 'updated': 1768161254040,\n",
            "                 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/us7000rp2k'},\n",
            "  'type': 'Feature'},\n",
            " {'geometry': {'coordinates': [141.7252, 39.5919, 79.657], 'type': 'Point'},\n",
            "  'id': 'us7000rp08',\n",
            "  'properties': {'alert': None,\n",
            "                 'cdi': 2.7,\n",
            "                 'code': '7000rp08',\n",
            "                 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us7000rp08&format=geojson',\n",
            "                 'dmin': 1.299,\n",
            "                 'felt': 2,\n",
            "                 'gap': 94,\n",
            "                 'ids': ',us7000rp08,',\n",
            "                 'mag': 5.2,\n",
            "                 'magType': 'mb',\n",
            "                 'mmi': None,\n",
            "                 'net': 'us',\n",
            "                 'nst': 81,\n",
            "                 'place': '19 km WSW of Miyako, Japan',\n",
            "                 'rms': 0.84,\n",
            "                 'sig': 417,\n",
            "                 'sources': ',us,',\n",
            "                 'status': 'reviewed',\n",
            "                 'time': 1768104937170,\n",
            "                 'title': 'M 5.2 - 19 km WSW of Miyako, Japan',\n",
            "                 'tsunami': 0,\n",
            "                 'type': 'earthquake',\n",
            "                 'types': ',dyfi,origin,phase-data,',\n",
            "                 'tz': None,\n",
            "                 'updated': 1768109228235,\n",
            "                 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/us7000rp08'},\n",
            "  'type': 'Feature'}]\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "metadata": {
        "id": "LEI2iGsZKux7"
      },
      "cell_type": "markdown",
      "source": [
        "#### Structured Data\n",
        "Notice how the data is organized\n",
        "\n",
        "- a dictionary with list of data \"records\"\n",
        "- each data \"record\" describes one earthquake\n",
        "- each \"earthquake\" is itself a dictionary of more dictionaries and lists\n",
        "\n",
        "This is typical for API results: a `dict` of `list`s of `dict`s of `list`s of `dict`s\n",
        "\n",
        "Understanding how data is structured is the first lesson for COMP215 - here we see how complex that can get even for a relatively simple data set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract earthquake data items from a list of dictionaries\n",
        "\n",
        "Goals:\n",
        "\n",
        "- create a data set suitable for counting the number of earthquakes per year\n",
        "- introduction to \"list comprehension\"\n",
        "- introduction to `datetime` objects\n",
        "\n",
        "We will use \"list comprehension\" to extract the list of dates and associated quake magnitude into \"parallel lists\".."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dAXX9kuZBH3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quake_timestamps = [quake['properties']['time'] for quake in earthquake_list] # List Comprehension #1: extract timestamps\n",
        "quake_mags = [quake['properties']['mag'] for quake in earthquake_list] # List Comprehension #2:  extract the magnitudes\n",
        "\n",
        "print('Timestamps:', quake_timestamps[:5])\n",
        "print('Magnitudes:', quake_mags[:5])"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JOFe4vNCBH3s",
        "outputId": "e57a2e9f-dd7b-4a7d-8361-93ca683e3fd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.379379Z",
          "start_time": "2025-12-31T20:09:06.373983Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamps: [1768160276651, 1768104937170, 1768077817306, 1768059248699, 1768058113989]\n",
            "Magnitudes: [5.1, 5.2, 5, 5, 5.2]\n"
          ]
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datetime.date\n",
        "Working with date strings is a pain.  So many formats!  Even within Canada, you might see:\n",
        "\"Jan. 9, 2023\" or \"09-01-2023\" or \"2023-01-09\" or ....\n",
        "Imagine trying to do a calculation like \"how many days between these 2 dates\"!!\n",
        "\n",
        "The build-in `datetime` package makes working with dates much easier.\n",
        "  * construct a `datetime` object from a \"timestamp\"  (typically the number of seconds since \"epoch\")\n",
        "  * \"parse\" the date string data (`strptime` ==  \"string-parse-datetime object\")\n",
        "  * get parts of the date (i.e., just the date without the time, or even just the year or month)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EfAZWGe_KuyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a datetime object from the \"timestamp\" - convert from ms to seconds, then convert from timestamp to datetime\n",
        "quake_dates = [\n",
        "    datetime.fromtimestamp(timestamp/1000) for timestamp in quake_timestamps\n",
        "]  # List Comprehension #3: transform each timestamp into a datetime object\n",
        "\n",
        "# but we only want the \"year\" part...\n",
        "quake_years = [dt.year for dt in quake_dates]  # List Comprehension #4: extrac year from each date\n",
        "quake_years[:5]"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.398233Z",
          "start_time": "2025-12-31T20:09:06.392217Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DL3KYtMKuyB",
        "outputId": "535e6b40-4c16-4315-cd9c-d9e900ab9d2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2026, 2026, 2026, 2026, 2026]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "execution_count": 25
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.416809Z",
          "start_time": "2025-12-31T20:09:06.414772Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz_lcFrEKuyD",
        "outputId": "0f1fc52d-2588-4847-8631-86427341f834"
      },
      "cell_type": "code",
      "source": [
        "# Now \"zip\" the year and magnitude data back together - this is a \"parallel list\" operation\n",
        "#     \"zip\" takes 2 or more lists and \"zips\" them together like a zipper - look it up!\n",
        "print('Zipped:')\n",
        "pprint(list(zip(quake_years[:5], quake_mags[:5])))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped:\n",
            "[(2026, 5.1), (2026, 5.2), (2026, 5), (2026, 5), (2026, 5.2)]\n"
          ]
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1 : loops vs. comprehensions\n",
        "\n",
        "In the code cell below, re-write the \"List Comprehensions\" above using one or more`for` loops so you understand how they work.\n",
        "\n",
        "Goal:\n",
        "\n",
        "- replicate the final zipped list of 2-tuples (year, magnitude) using the \"list accumulator\" algorithm you learned in 115\n",
        "\n",
        "Compare to see how a \"list comprehension\" is a compact way to write a \"list accumulator\" algorithm (and more efficient too!)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "koVKiju9BH3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ex. 1 your code here\n",
        "\n",
        "from itertools import islice\n",
        "\n",
        "my_year_mag = []\n",
        "\n",
        "for my_quake_year in quake_dates:\n",
        "  for my_earthquake_mag in earthquake_list:\n",
        "    my_year_mag.append((my_quake_year.year, my_earthquake_mag['properties']['mag']))\n",
        "\n",
        "print(my_year_mag)\n",
        "#print(list(islice(my_year_mag, 5)))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "aa5xLcWEBH3t",
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.428326Z",
          "start_time": "2025-12-31T20:09:06.426417Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "s-8Ql74wKuyG"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise 2:  counting dates\n",
        "\n",
        "In the code cell below, write an algorithm that counts the number of quakes in each year.\n",
        "\n",
        "Goal:\n",
        "\n",
        "- produce a dictionary that maps each year in the data set to a count of the number of quakes in that year\n",
        "- an mock example of the data structure you are aiming for is given below\n",
        "\n",
        "_Hints_:\n",
        "\n",
        "- this is also an \"accumulator\" algorithm, where you are accumulating a count for each year\n",
        "- a `defaultdict` can simplify the algorithm - look it up if you are interested (not required)\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.441613Z",
          "start_time": "2025-12-31T20:09:06.439795Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb7OZMdQKuyH",
        "outputId": "fdc54d9d-df10-4fce-b012-b2676c26b996"
      },
      "cell_type": "code",
      "source": [
        "# Ex. 2 your code here\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "earthquake_counts = defaultdict(int)\n",
        "\n",
        "for my_quake_year in quake_years:\n",
        "  earthquake_counts[my_quake_year] += 1\n",
        "\n",
        "print(earthquake_counts)\n",
        "\n",
        "# Replace this \"mock\" data with your results - these data are plotted in next step...\n",
        "earthquake_counts = {\n",
        "    2022: 1726,\n",
        "    2023: 1780,\n",
        "    2024: 1507,\n",
        "    2025: 2133,\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {2026: 58, 2025: 2133, 2024: 1507, 2023: 1780, 2022: 1726})\n"
          ]
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating a plot\n",
        "\n",
        "Finally, we'll plot the (year, earthquake_count) data as a nice x-y line graph...."
      ],
      "metadata": {
        "collapsed": false,
        "id": "2ow28BuTBH3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(earthquake_counts.keys(), earthquake_counts.values())\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(f\"Number of Earthquakes (Magnitude ≥ {params['minmagnitude']})\")\n",
        "plt.title(f\"Earthquakes per Year Since {params['starttime']}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "FgwPH8mTBH3v",
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.575905Z",
          "start_time": "2025-12-31T20:09:06.452470Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3: re-run the analysis for a different data set\n",
        "\n",
        "Repeat the analysis above, but this time for large-magnitude earthquakes (e.g., >=7) over a longer timespan (e.g., since 1970).\n",
        "(Note that the API limits results to 20,000 records, if it fails, reduce the size of your query.)\n",
        "\n",
        "* Just re-run the analysis with new parameters!\n",
        "* Submit your lab workbook run with your final analysis parameters\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "zGw7XmGTKuyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge Exercises (optional) - Take your skills to the next level...\n",
        "\n",
        "## Exercise 4: Earthquakes by month\n",
        "\n",
        "1. re-do the data transformations to extract (dt.year, dt.month) 2-tuples from each earthquake timestamp\n",
        "2. re-do the count analysis to tally the number of quakes in each month\n",
        "3. create a new plot with the number of quakes per month\n",
        "\n",
        "- Develop all the code for this exercise in one or more code blocks below.\n",
        "- You may copy any of the code from blocks above, then revise it to do the monthly analysis.\n",
        "- Change the variable names you use (e.g., `quake_months` instead of `quake_years`) to avoid getting confused\n",
        "\n",
        "#### Exercise 5: Smoothing function super-challenge!\n",
        "\n",
        "Notice that the data plot looks quite erratic.  Earthquakes are \"self-organizing\", \"critical\" systems, which we'll learn\n",
        "more about later in the term.  Their erratic behaviour makes it hard to spot long-term trends.\n",
        "\n",
        " * One technique to help highlight trends is to \"smooth\" the data using a \"6-month rolling average\".\n",
        "Each month, we take the average of the previous 6 months of earthquake counts.\n",
        " * Add new code cell below, compute the 6-month rolling average for each month from the raw monthly count data.\n",
        " * Create a plot to display the rolling average data and compare your plot with the one produced in Ex. 4.\n",
        "\n",
        " Hints: you are free to do this however you like, but a quite elegant solution uses list comprehension, range, and slices"
      ],
      "metadata": {
        "collapsed": false,
        "id": "qqeTORnvBH3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ex. 4 (challenge) your code here"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-12-31T20:09:06.591955Z",
          "start_time": "2025-12-31T20:09:06.590042Z"
        },
        "id": "Abz1vn6DKuyM"
      },
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "lab1.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}